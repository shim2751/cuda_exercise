# **병렬 리덕션 (Parallel Reduction)**

병렬 리덕션(Parallel Reduction) 커널의 최적화는 수많은 스레드가 협력하여 단일 결과값을 도출하는 과정에서 발생하는 다양한 병목 현상을 단계적으로 해결하는 것을 목표로 합니다.  
최적화 과정은 **제어 및 메모리 접근의 비효율성(Divergence) 최소화 → GPU 메모리 계층 구조의 적극적 활용 → 병렬화 오버헤드 감소**의 순서로 점진적으로 진행됩니다.

---
## **Experiment Results**

### **num of elements: 512**
| Kernel                | Excution time (ms) |
|----------------------------|----------------|
| **Basic Reduction**          | 43.451393 ms    |
| **Min Control Div**  | 0.024576 ms     |
| **Shared Mem** | 0.019456 ms  |
| **Hierarchical Reduction**   | 0.018432 ms  |
| **Coarsened Reduction:**   | 0.026624 ms  |


### **num of elements: 1024*1024**  
| Kernel                | Excution time (ms) |
|----------------------------|----------------|
| **Hierarchical Reduction**   | 0.016384 ms  |
| **Coarsened Reduction:**   | 0.011264 ms  |

---

## **1단계: 기본 리덕션 커널과 발산 문제**

### **원리 및 문제점**
- 가장 기본적인 병렬 리덕션은 여러 스레드가 인접한 데이터를 병렬로 더해가며 단계적으로 결과값을 좁혀가는 **트리(Tree) 구조**를 가집니다.
- 각 스레드는 특정 메모리 위치(예: 짝수 인덱스)를 할당받아 해당 위치의 업데이트를 책임지는 **"Owner-computes"** 방식을 사용합니다.
- 하지만 단계가 진행될수록 **액티브 스레드(Active Thread)**들의 간격이 점점 벌어지게 됩니다.

### **핵심 문제: 제어 및 메모리 발산 (Control & Memory Divergence)**
- **제어 발산 (Control Divergence)**  
  워프(Warp) 내 일부 스레드만 활성화되고 나머지는 유휴 상태가 되어 실행 유닛 활용도가 급격히 떨어집니다.
- **메모리 발산 (Memory Divergence)**  
  인접한 스레드들이 서로 떨어진 메모리 위치에 접근하므로 메모리 접근이 **통합(Coalesced)**되지 못하고 불필요한 메모리 트랜잭션이 발생하여 대역폭을 낭비합니다.

---

## **2단계: 발산 최소화 커널 (Sequential Addressing)**

### **최적화 원리**
- 스레드와 데이터 인덱스 매핑을 변경하여 **액티브 스레드들이 항상 연속적인 인덱스**(예: `threadIdx.x = 0~N-1`)를 가지도록 재구성합니다.
- 첫 단계에서는 스레드들이 멀리 떨어진 데이터를 가져와 더하고, 이후 단계로 갈수록 접근 거리를 줄이는 방식을 사용합니다.
- 연산자는 덧셈처럼 **교환 법칙(Commutative)**과 **결합 법칙(Associative)**을 만족해야 합니다.

### **핵심 효과**
- **제어 발산 감소**  
  액티브 스레드들이 연속적으로 모여 워프 단위로 함께 비활성화되므로 워프 내 발산을 최소화할 수 있습니다.
- **메모리 접근 통합**  
  인접한 스레드가 인접한 메모리 주소에 접근하므로 **완벽한 메모리 Coalescing**을 달성할 수 있습니다.

---

## **3단계: 공유 메모리 활용**

### **최적화 원리**
- 리덕션 중간 결과(Partial Sum)를 빠른 **온칩 공유 메모리(Shared Memory)**에 저장합니다.
- 각 스레드는 글로벌 메모리에서 데이터를 한 번만 읽어 공유 메모리에 저장하고, 이후 모든 리덕션 연산은 공유 메모리에서만 수행합니다.

### **핵심 효과**
- **글로벌 메모리 접근 최소화**  
  비용이 비싼 글로벌 메모리 접근 횟수를 줄여 성능을 크게 개선합니다.
- **원본 배열 보존**  
  입력 데이터를 수정하지 않고 보존할 수 있습니다.

---

## **4단계: 계층적 리덕션 및 원자적 연산 (확장성 확보)**

### **필요성**
- **단일 블록의 한계 극복**  
  스레드 블록 내 스레드들은 __syncthreads()를 통해 동기화할 수 있지만, 서로 다른 블록 간에는 간단한 동기화 방법이 없습니다.
- **다중 블록 병렬화**  
  계층적 리덕션을 통해 여러 블록이 서로 다른 구간을 병렬로 처리하고 결과를 합산할 수 있어 **대규모 데이터 처리 성능을 획기적으로 향상**시킵니다.

### **최적화 원리**
- 단일 블록 용량(예: 1024 스레드)을 넘어서는 큰 배열을 **세그먼트(Segment)**로 나눕니다.
- 각 블록은 할당된 세그먼트에서 공유 메모리를 사용해 독립적으로 리덕션을 수행하고 **중간 결과(Partial Sum)**를 계산합니다.
- 모든 블록이 계산을 마친 후, 각 블록의 결과를 **`atomicAdd()`** 같은 **원자적 연산(Atomic Operation)**으로 안전하게 더하여 최종 결과를 얻습니다.

### **핵심 효과**
- **확장성 (Scalability)**  
  여러 블록을 동시에 활용하여 큰 입력 데이터에 대해서도 효율적인 리덕션이 가능합니다.

---

## **5단계: 스레드 거칠기 (Thread Coarsening)**

### **필요성**
- **스레드 관리 오버헤드 감소**  
  너무 많은 스레드를 사용하는 것은 워프 스케줄링과 동기화(`__syncthreads()`)에 따른 오버헤드를 증가시킵니다.
- **계산 집중도 향상**  
  GPU 하드웨어의 실행 유닛(코어) 수는 한정되어 있습니다. 처리할 데이터가 매우 많아 수많은 스레드 블록을 실행해야 할 때, 하드웨어는 이 블록들을 한 번에 처리하지 못하고 여러 그룹으로 나누어 순차적으로 실행하게 됩니다.  
  한 스레드가 여러 데이터를 순차적으로 처리함으로써 메모리 접근 대비 연산 비율(Compute-to-Memory Ratio)을 높여 **GPU 코어 활용률을 개선**할 수 있습니다.
  
### **최적화 원리**
- 하나의 스레드가 처리하는 데이터 양을 늘려 **레지스터(Register)** 변수에 자신만의 중간 합을 계산한 후 공유 메모리 리덕션에 참여합니다.

### **핵심 효과**
- **병렬화 오버헤드 감소**  
  스레드 수와 동기화 호출 빈도를 줄여 실행 효율을 높입니다.
- 하드웨어가 여러 블록을 순차적으로 실행해야 하는 경우, **'거친' 스레드 구성**이 동기화와 메모리 접근 비용을 줄여 성능을 개선합니다.

---

## **최종 결론**
병렬 리덕션 커널의 최적화는 GPU 아키텍처를 깊이 이해하고 **점진적으로 병목을 제거하는 과정**입니다.

1. **발산 문제 해결** → 워프 실행 효율 향상  
2. **메모리 계층 활용 극대화** → 레지스터 & 공유 메모리 사용  
3. **계층적 리덕션과 Thread Coarsening 필요성** → **확장성**과 **오버헤드 감소**를 동시에 달성  
4. **병렬화 부가 비용 최소화** → 높은 성능의 리덕션 커널 구현 가능
