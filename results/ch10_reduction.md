# **Reduction**

Reduction 커널의 최적화는 수많은 스레드가 협력하여 단일 결과값을 도출하는 과정에서 발생하는 다양한 병목 현상을 단계적으로 해결하는 것을 목표로 합니다.  
최적화 과정은 **제어 및 메모리 접근의 비효율성(Divergence) 최소화 → GPU 메모리 계층 구조의 적극적 활용 → 병렬화 오버헤드 감소**의 순서로 점진적으로 진행됩니다.

---
## **Experiment Results**

### **# of elements: 512**
| Kernel                | Excution time (ms) |
|----------------------------|----------------|
| **Basic Reduction**          | 43.451393 ms    |
| **Min Control Div**  | 0.024576 ms     |
| **Shared Mem** | 0.019456 ms  |
| **Hierarchical Reduction**   | 0.018432 ms  |
| **Coarsened Reduction:**   | 0.026624 ms  |


### **\# of elements: 1024*1024**  
| Kernel                | Excution time (ms) |
|----------------------------|----------------|
| **Hierarchical Reduction**   | 0.016384 ms  |
| **Coarsened Reduction:**   | 0.011264 ms  |

---

## **1단계: A Simple Sum Reduction Kernel**

### **원리 및 문제점**
- 가장 기본적인 병렬 리덕션은 여러 스레드가 인접한 데이터를 병렬로 더해가며 단계적으로 결과값을 좁혀가는 **트리(Tree) 구조**를 가집니다.
- 각 스레드는 특정 메모리 위치(예: 짝수 인덱스)를 할당받아 해당 위치의 업데이트를 책임지는 **"Owner-computes"** 방식을 사용합니다.
- 하지만 단계가 진행될수록 **Active Thread**들의 간격이 점점 벌어지게 됩니다.

### **핵심 문제: Control & Memory Divergence**
- **Control Divergence**  
  워프(Warp) 내 일부 스레드만 활성화되고 나머지는 유휴 상태가 되어 실행 유닛 활용도가 급격히 떨어집니다.
- **Memory Divergence**  
  인접한 스레드들이 서로 떨어진 메모리 위치에 접근하므로 메모리 접근이 **Coalesced**되지 못하고 불필요한 메모리 트랜잭션이 발생하여 대역폭을 낭비합니다.

---

## **2단계: Minimizing Divergence**

### **최적화 원리**
- 스레드와 데이터 인덱스 매핑을 변경하여 **액티브 스레드들이 항상 연속적인 인덱스**(예: `threadIdx.x = 0~N-1`)를 가지도록 재구성합니다.
- 첫 단계에서는 스레드들이 멀리 떨어진 데이터를 가져와 더하고, 이후 단계로 갈수록 접근 거리를 줄이는 방식을 사용합니다.
- 연산자는 덧셈처럼 **Commutative**과 **Associative**을 만족해야 합니다.

### **핵심 효과**
- **Minimizing Control Divergence**  
  액티브 스레드들이 연속적으로 모여 워프 단위로 함께 비활성화되므로 워프 내 발산을 최소화할 수 있습니다.
- **Minimizing Memory Divergence**  
  인접한 스레드가 인접한 메모리 주소에 접근하므로 **Coalescing**을 달성할 수 있습니다.

---

## **3단계: Access Shared Memory**

### **최적화 원리**
- 리덕션 중간 결과(Partial Sum)를 빠른 **Shared Memory**에 저장합니다.
- 각 스레드는 글로벌 메모리에서 데이터를 한 번만 읽어 공유 메모리에 저장하고, 이후 모든 리덕션 연산은 공유 메모리에서만 수행합니다.

### **핵심 효과**
- **Minimizing Global Memory Accesses**  
  비용이 비싼 글로벌 메모리 접근 횟수를 줄여 성능을 크게 개선합니다.

---

## **4단계: Hierarchical Reduction for Arbitrary Input Length**

### **필요성**
- **단일 블록의 한계 극복**  
  스레드 블록 내 스레드들은 __syncthreads()를 통해 동기화할 수 있지만, 서로 다른 블록 간에는 간단한 동기화 방법이 없습니다.
- **다중 블록 병렬화**  
  계층적 리덕션을 통해 여러 블록이 서로 다른 구간을 병렬로 처리하고 결과를 합산할 수 있어 **대규모 데이터 처리 성능을 획기적으로 향상**시킵니다.

### **최적화 원리**
- 단일 블록 용량(예: 1024 스레드)을 넘어서는 큰 배열을 **Segment**로 나눕니다.
- 각 블록은 할당된 세그먼트에서 공유 메모리를 사용해 독립적으로 리덕션을 수행하고 **Partial Sum**를 계산합니다.
- 모든 블록이 계산을 마친 후, 각 블록의 결과를 **`atomicAdd()`** 같은 **Atomic Operation**으로 안전하게 더하여 최종 결과를 얻습니다.

### **핵심 효과**
- **Scalability**  
  여러 블록을 동시에 활용하여 큰 입력 데이터에 대해서도 효율적인 리덕션이 가능합니다.

---

## **5단계: Thread Coarsening**

### **필요성**
- **비효율성**  
  많은 스레드 블록을 만들면, control divergence과 같은 **비효율적인 단계를 모든 블록이 반복**하게 됩니다
- **하드웨어 자원의 한계 고려**  
  GPU가 동시에 실행할 수 있는 스레드 블록의 수는 정해져 있습니다. 만약 처리할 데이터가 너무 많아 생성된 스레드 블록의 수가 하드웨어의 동시 실행 용량을 초과하면 하드웨어는 이 블록들을 한 번에 처리하지 못하고 여러 그룹으로 나누어 순차적으로 실행하게 됩니다.
  
### **최적화 원리**
- 하나의 스레드가 처리하는 데이터 양을 늘리고 **레지스터(Register)** 변수에 자신만의 중간 합을 계산한 후 공유 메모리 리덕션에 참여합니다.

### **핵심 효과**
- 하드웨어가 여러 블록을 순차적으로 실행해야 하는 경우, **Thread Coarsening**이 동기화와 메모리 접근 비용을 줄여 성능을 개선합니다.

---

## **최종 결론**
1. **Divergence 문제 해결** → 워프 실행 효율 향상  
2. **메모리 계층 활용 극대화** → 레지스터 & 공유 메모리 사용  
3. **Hierarchical Reduction & Thread Coarsening 필요성** → **확장성**과 **자원 활용도 증가**를 동시에 달설
